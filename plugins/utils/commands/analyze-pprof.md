---
description: Aggregate and analyze CPU profiles from one or more pprof directories
argument-hint: "<dir1> [dir2 ...]"
---

## Name
utils:analyze-pprof

## Synopsis
```
/utils:analyze-pprof <directory1> [directory2 ...]
```

## Description

The `analyze-pprof` command aggregates CPU profile data from pprof files in one or more directories and generates a comprehensive analysis report. It identifies which components, functions, and code paths consume the most CPU time.

When multiple directories are provided, the command also performs comparative analysis to highlight significant differences in CPU usage patterns between the datasets.

This command is useful for:
- Performance profiling and optimization
- Identifying CPU hotspots in applications
- Comparing CPU usage across different builds or configurations
- Understanding resource consumption patterns
- Performance regression analysis

## Prerequisites

Before using this command, ensure you have:

1. **Go toolchain**
   - Required for `go tool pprof` command
   - Install from: https://go.dev/doc/install
   - Verify with: `go version`

2. **Python 3**
   - Required for aggregation script
   - Verify with: `python3 --version`

3. **pprof CPU profile files**
   - Files should be in pprof format (typically generated by Go runtime)
   - Common file patterns: `*.pprof`, `cpu.prof`, `profile.pb.gz`
   - Located in one or more directories

## Arguments

- **directory1** (required): First directory containing pprof CPU profile files
- **directory2, directory3, ...** (optional): Additional directories for comparative analysis
  - When multiple directories are provided, the command compares their CPU usage patterns
  - Each directory should contain one or more pprof files to aggregate

## Implementation

The command performs the following analysis:

### 1. Validate Prerequisites

Check for required tools:

```bash
if ! command -v go &> /dev/null; then
    echo "Error: Go toolchain not found. Install from https://go.dev/doc/install"
    exit 1
fi

if ! command -v python3 &> /dev/null; then
    echo "Error: Python 3 not found"
    exit 1
fi
```

### 2. Validate Input Directories

For each provided directory:

```bash
for dir in "$@"; do
    if [ ! -d "$dir" ]; then
        echo "Error: Directory not found: $dir"
        exit 1
    fi

    # Count pprof files
    pprof_count=$(find "$dir" -type f \( -name "*.pprof" -o -name "*.prof" -o -name "*.pb.gz" -o -name "profile" \) 2>/dev/null | wc -l)

    if [ "$pprof_count" -eq 0 ]; then
        echo "Warning: No pprof files found in $dir"
        echo "  Looking for files matching: *.pprof, *.prof, *.pb.gz, or named 'profile'"
    else
        echo "Found $pprof_count pprof file(s) in $dir"
    fi
done
```

### 3. Create Working Directory

Set up workspace for analysis:

```bash
# Use basename of first directory as identifier
dir_name=$(basename "$1")
timestamp=$(date +%Y%m%d_%H%M%S)
work_dir=".work/analyze-pprof/${dir_name}_${timestamp}"

mkdir -p "$work_dir"
echo "Working directory: $work_dir"
```

### 4. Aggregate and Analyze Each Directory

For each directory, use the Python helper script to aggregate pprof data:

```bash
# Path to the helper script
script_path="plugins/utils/skills/analyze-pprof/analyze_pprof.py"

# Process each directory
for i in "${!directories[@]}"; do
    dir="${directories[$i]}"
    label="dataset_$((i+1))"

    echo ""
    echo "==============================================="
    echo "ANALYZING: $dir (Label: $label)"
    echo "==============================================="

    # Run analysis
    python3 "$script_path" \
        --input-dir "$dir" \
        --output-dir "$work_dir" \
        --label "$label" \
        --format text

    # Store results for comparison
    results_file="$work_dir/${label}_summary.json"
done
```

### 5. Generate Individual Reports

For each directory, generate detailed analysis:

```bash
# Top functions by cumulative CPU time
echo "Top 20 functions by cumulative CPU time:"
go tool pprof -top -cum "$merged_profile" | head -25

echo ""

# Top functions by flat CPU time (self time)
echo "Top 20 functions by flat CPU time:"
go tool pprof -top "$merged_profile" | head -25

echo ""

# Call graph for most expensive functions
echo "Call graph of top 10 functions:"
go tool pprof -tree -cum "$merged_profile" | head -50
```

### 6. Perform Comparative Analysis (if multiple directories)

When multiple directories are provided:

```bash
if [ ${#directories[@]} -gt 1 ]; then
    echo ""
    echo "==============================================="
    echo "COMPARATIVE ANALYSIS"
    echo "==============================================="
    echo ""

    # Use Python script to compare datasets
    python3 "$script_path" \
        --compare \
        --input-dir "$work_dir" \
        --output-file "$work_dir/comparison_report.txt"

    cat "$work_dir/comparison_report.txt"
fi
```

### 7. Generate Final Report

Create a comprehensive HTML report:

```bash
report_file="$work_dir/pprof_analysis_report.html"

echo ""
echo "Generating final report: $report_file"

# Generate interactive HTML report using go tool pprof
for i in "${!directories[@]}"; do
    dir="${directories[$i]}"
    label="dataset_$((i+1))"
    merged_profile="$work_dir/${label}_merged.pprof"

    if [ -f "$merged_profile" ]; then
        go tool pprof -http=:0 -no_browser "$merged_profile" &
        pprof_pid=$!

        # Save flamegraph to file
        go tool pprof -output="$work_dir/${label}_flamegraph.svg" -svg "$merged_profile"

        kill $pprof_pid 2>/dev/null || true
    fi
done

echo "Analysis complete!"
echo ""
echo "Output files:"
echo "  - Text reports: $work_dir/*_summary.txt"
echo "  - JSON data: $work_dir/*_summary.json"
echo "  - Merged profiles: $work_dir/*_merged.pprof"
echo "  - Flamegraphs: $work_dir/*_flamegraph.svg"
if [ ${#directories[@]} -gt 1 ]; then
    echo "  - Comparison: $work_dir/comparison_report.txt"
fi
```

## Return Value

- **Exit 0**: Analysis completed successfully
- **Exit 1**: Error occurred (missing prerequisites, invalid directories, etc.)

**Output Format**:
- Text summaries showing top CPU consumers
- JSON files with structured data
- Merged pprof files for further analysis
- SVG flamegraphs for visualization
- Comparative analysis report (when multiple directories provided)

**Output Location**: `.work/analyze-pprof/{directory}_{timestamp}/`

## Examples

### Example 1: Analyze single directory

```
/utils:analyze-pprof ./profiles/baseline
```

Output:
```
Found 15 pprof file(s) in ./profiles/baseline
Working directory: .work/analyze-pprof/baseline_20260112_143025

===============================================
ANALYZING: ./profiles/baseline (Label: dataset_1)
===============================================

Merging 15 pprof files...
Merged profile size: 42.3 MB

Top 20 functions by cumulative CPU time:
  flat  flat%   sum%        cum   cum%
  2.5s  5.2%  5.2%     25.3s 52.8%  runtime.mallocgc
  1.8s  3.8%  9.0%     18.7s 39.0%  encoding/json.Unmarshal
  3.2s  6.7% 15.7%     15.4s 32.1%  crypto/tls.(*Conn).Write
  ...

Analysis complete!

Output files:
  - Text reports: .work/analyze-pprof/baseline_20260112_143025/dataset_1_summary.txt
  - JSON data: .work/analyze-pprof/baseline_20260112_143025/dataset_1_summary.json
  - Merged profiles: .work/analyze-pprof/baseline_20260112_143025/dataset_1_merged.pprof
  - Flamegraphs: .work/analyze-pprof/baseline_20260112_143025/dataset_1_flamegraph.svg
```

### Example 2: Compare two directories

```
/utils:analyze-pprof ./profiles/before ./profiles/after
```

Output:
```
Found 12 pprof file(s) in ./profiles/before
Found 14 pprof file(s) in ./profiles/after
Working directory: .work/analyze-pprof/before_20260112_143530

===============================================
ANALYZING: ./profiles/before (Label: dataset_1)
===============================================
[... analysis output ...]

===============================================
ANALYZING: ./profiles/after (Label: dataset_2)
===============================================
[... analysis output ...]

===============================================
COMPARATIVE ANALYSIS
===============================================

Top CPU Usage Changes:
  Function                                     Before    After     Change
  runtime.mallocgc                            25.3s     18.2s     -28.1% ▼
  encoding/json.Unmarshal                     18.7s     22.4s     +19.8% ▲
  crypto/tls.(*Conn).Write                    15.4s     14.9s      -3.2% ▼
  net/http.(*conn).serve                      12.1s     15.8s     +30.6% ▲
  ...

Significant Regressions (>20% increase):
  - net/http.(*conn).serve: +30.6% (+3.7s)
  - database/sql.(*DB).Query: +45.2% (+5.8s)

Significant Improvements (>20% decrease):
  - runtime.mallocgc: -28.1% (-7.1s)
  - io.Copy: -32.4% (-4.2s)

New hotspots (not present in before):
  - github.com/org/pkg.NewFunction: 8.3s (17.3%)

Removed hotspots (not present in after):
  - github.com/org/old.LegacyFunction: 6.2s (12.9%)

Analysis complete!

Output files:
  - Text reports: .work/analyze-pprof/before_20260112_143530/dataset_*_summary.txt
  - JSON data: .work/analyze-pprof/before_20260112_143530/dataset_*_summary.json
  - Merged profiles: .work/analyze-pprof/before_20260112_143530/dataset_*_merged.pprof
  - Flamegraphs: .work/analyze-pprof/before_20260112_143530/dataset_*_flamegraph.svg
  - Comparison: .work/analyze-pprof/before_20260112_143530/comparison_report.txt
```

### Example 3: Analyze multiple configurations

```
/utils:analyze-pprof ./profiles/config-a ./profiles/config-b ./profiles/config-c
```

Compares CPU usage across three different configurations.

## Common Use Cases

### Performance Optimization

**Scenario**: Identify performance bottlenecks in an application

**Workflow**:
1. Collect CPU profiles during representative workload
2. Run `/utils:analyze-pprof ./profiles`
3. Review top functions by cumulative time
4. Optimize identified hotspots
5. Collect new profiles and compare

### Regression Detection

**Scenario**: Verify that code changes don't introduce performance regressions

**Workflow**:
1. Collect baseline profiles before changes
2. Make code modifications
3. Collect new profiles after changes
4. Run `/utils:analyze-pprof ./baseline ./current`
5. Review comparative analysis for regressions

### A/B Testing

**Scenario**: Compare performance of different implementations

**Workflow**:
1. Collect profiles for each implementation variant
2. Run `/utils:analyze-pprof ./variant-a ./variant-b`
3. Analyze which variant has better CPU characteristics

### Capacity Planning

**Scenario**: Understand CPU consumption under different load levels

**Workflow**:
1. Collect profiles at various load levels (low, medium, high)
2. Run `/utils:analyze-pprof ./load-low ./load-medium ./load-high`
3. Identify how CPU usage scales with load

## Understanding the Output

### Flat vs Cumulative Time

- **Flat time**: CPU time spent directly in the function (self time)
- **Cumulative time**: CPU time spent in the function plus all functions it calls

**Example**:
```
  flat  flat%   sum%        cum   cum%
  2.5s  5.2%  5.2%     25.3s 52.8%  runtime.mallocgc
```
- Spent 2.5s directly in `mallocgc` (5.2% of total)
- Spent 25.3s in `mallocgc` and its callees (52.8% of total)

### Interpreting Percentages

- **sum%**: Cumulative percentage up to this line
- **cum%**: Percentage of total time including callees
- **flat%**: Percentage of total time in function only

### Flamegraphs

Flamegraphs (SVG files) provide visual representation:
- Width of each bar = CPU time
- Y-axis = call stack depth
- Color = different functions/packages
- Hover for details

## Security Considerations

- Profile files may contain function names and stack traces
- Treat profiles as confidential if they reveal internal implementation details
- Be cautious when sharing profiles from production systems
- Profiles may contain information about data structures and algorithms

## See Also

- Go pprof documentation: https://pkg.go.dev/runtime/pprof
- Go blog on profiling: https://go.dev/blog/pprof
- Flamegraph visualization: https://www.brendangregg.com/flamegraphs.html
- Related command: `/utils:generate-test-plan`

## Notes

- This command uses `go tool pprof` which requires Go to be installed
- Multiple pprof files in a directory are automatically merged for aggregation
- Merging is additive: samples from all files are combined
- For accurate comparison, ensure profile durations are similar across datasets
- Profiles should be collected under similar conditions for meaningful comparison
- The command automatically detects pprof files by common naming patterns
- Custom file patterns can be added to the helper script if needed
- SVG flamegraphs can be opened in any web browser
- For interactive analysis, use: `go tool pprof -http=:8080 merged.pprof`
- Large profile files (>100MB) may require significant memory to process
